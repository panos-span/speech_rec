\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{alphabeta}
\usepackage{amsmath}
\usepackage{float}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{booktabs}  % For better looking tables
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{breakurl}
\usepackage{listings}
\usepackage[numbers]{natbib}
\usepackage{subcaption}  % Προσθέστε αυτή τη γραμμή στο preample του εγγράφου

\lstset{
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  language=Bash,
  extendedchars=true,
  literate={β}{{\beta}}1
}

%\title{Αναγνώριση Προτύπων \\ 2η Εργαστηριακή Άσκηση \\ Χειμερινό Εξάμηνο 2024-2025 \\ Ε.ΔE.ΜΜ}
%\author{Σπανάκης Παναγιώτης-Αλέξιος (ΑΜ: 03400274)}
%\date{16/12/2024}

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \Large
        \textbf{ΕΘΝΙΚΟ ΜΕΤΣΟΒΙΟ ΠΟΛΥΤΕΝΧΕΙΟ}
        
        \vspace*{0.5cm}

        \large 
        Δ.Π.Μ.Σ. Ε.ΔΕ.ΜΜ
        %\includegraphics{ntua.png}

        \large
        \textbf{\\Επεξεργασία Φωνής και Φυσικής Γλώσσας}
        
        
        
        \vspace{2.5cm}
        \small
        \textit{$1^η$ Εργαστηριακή άσκηση}        
        
        %%% First option %%%

        % \vspace{2.5cm}
        % \large
        % \vfill
        % Σπανάκης Παναγιώτης-Αλέξιος 
        % \\Α.Μ.: 09321011 

        % \vspace{2.5cm}
        % \large
        % \vfill % 
        % Ιωάννης Καραπαρίσης 
        % \\Α.Μ.: 09321011 
    
    \end{center}
    
    %% SECOND OPTION %%%%
    
    \begin{flushright}
        \vfill
        Σπανάκης Παναγιώτης-Αλέξιος
        \\Α.Μ.: 03400274
        \\e-mail: spanakis01@gmail.com
    \end{flushright}

    \begin{flushleft}
        \vfill
        Ιωακείμ Ελ-Χαττάμπ Μπιστρογιάννης
        \\Α.Μ.: 
        \\e-mail: @gmail.com
    \end{flushleft}
    
    %%
\end{titlepage}

\newpage


\section{Θεωρητικό Υπόβαθρο}

\subsection{Mel-Frequency Cepstral Coefficients (MFCCs)}

Τα Mel-Frequency Cepstral Coefficients (MFCCs) αποτελούν ένα από τα πιο διαδεδομένα ακουστικά χαρακτηριστικά που χρησιμοποιούνται στην αναγνώριση ομιλίας. Η εξαγωγή τους βασίζεται στην ανάλυση των σημάτων φωνής με μια ειδικά σχεδιασμένη συστοιχία φίλτρων (Mel filterbank), η οποία είναι εμπνευσμένη από τον μη γραμμικό τρόπο με τον οποίο το ανθρώπινο αυτί αντιλαμβάνεται τις συχνότητες του ήχου.

Η διαδικασία εξαγωγής των MFCCs περιλαμβάνει τα εξής βήματα:

\begin{enumerate}
    \item Διαίρεση του σήματος σε μικρά τμήματα (frames) με επικάλυψη
    \item Εφαρμογή παραθύρου (συνήθως Hamming) σε κάθε frame
    \item Υπολογισμός του μετασχηματισμού Fourier (FFT)
    \item Εφαρμογή φίλτρων Mel-scale στο φάσμα ισχύος
    \item Λογαρίθμηση των ενεργειών που προκύπτουν
    \item Εφαρμογή Διακριτού Μετασχηματισμού Συνημιτόνου (DCT)
    \item Επιλογή των πρώτων συντελεστών (συνήθως 12-13) ως MFCCs
\end{enumerate}

Τα MFCCs είναι ιδιαίτερα χρήσιμα επειδή συμπυκνώνουν τις πληροφορίες του φάσματος του σήματος με τρόπο που προσομοιάζει την ανθρώπινη αντίληψη του ήχου, δίνοντας μεγαλύτερη έμφαση στις χαμηλές συχνότητες.

\subsection{Γλωσσικά Μοντέλα (Language Models)}

Τα γλωσσικά μοντέλα (Language Models) στην αναγνώριση ομιλίας αναπαριστούν την πιθανότητα εμφάνισης συγκεκριμένων ακολουθιών λέξεων ή φωνημάτων στη γλώσσα. Στην παρούσα άσκηση χρησιμοποιήσαμε στατιστικά γλωσσικά μοντέλα n-gram, συγκεκριμένα unigram και bigram μοντέλα, για την αναπαράσταση των πιθανοτήτων εμφάνισης μεμονωμένων φωνημάτων και ζευγών φωνημάτων, αντίστοιχα.

Τα n-gram μοντέλα βασίζονται στην υπόθεση Markov, υποθέτοντας ότι η πιθανότητα εμφάνισης ενός φωνήματος εξαρτάται μόνο από τα $n-1$ προηγούμενα φωνήματα. Έτσι:

\begin{itemize}
    \item Στο unigram μοντέλο, η πιθανότητα κάθε φωνήματος θεωρείται ανεξάρτητη από τα προηγούμενα φωνήματα.
    \item Στο bigram μοντέλο, η πιθανότητα κάθε φωνήματος εξαρτάται μόνο από το αμέσως προηγούμενο φώνημα.
\end{itemize}

Η ποιότητα ενός γλωσσικού μοντέλου μπορεί να αξιολογηθεί με τη μετρική perplexity, η οποία αντιπροσωπεύει το μέσο αριθμό εναλλακτικών επιλογών που "βλέπει" το μοντέλο σε κάθε βήμα πρόβλεψης. Χαμηλότερες τιμές perplexity υποδεικνύουν καλύτερο γλωσσικό μοντέλο.

\subsection{Φωνητικά Μοντέλα (Acoustic Models)}

Τα φωνητικά μοντέλα (Acoustic Models) αναπαριστούν τη σχέση μεταξύ των ακουστικών χαρακτηριστικών του σήματος ομιλίας και των φωνητικών μονάδων (φωνήματα στην περίπτωσή μας). Στην άσκηση αυτή, χρησιμοποιήσαμε δύο τύπους ακουστικών μοντέλων:

\begin{enumerate}
    \item \textbf{Μονοφωνικό GMM-HMM}: Σε αυτό το μοντέλο, κάθε φώνημα μοντελοποιείται ανεξάρτητα από το φωνητικό του περιβάλλον, χρησιμοποιώντας ένα Κρυφό Μαρκοβιανό Μοντέλο (HMM) με καταστάσεις που οι πιθανότητες εκπομπής τους μοντελοποιούνται με Μείγματα Γκαουσιανών Κατανομών (GMM).
    
    \item \textbf{Τριφωνικό GMM-HMM}: Σε αυτό το πιο σύνθετο μοντέλο, κάθε φώνημα μοντελοποιείται λαμβάνοντας υπόψη το φωνητικό του περιβάλλον, δηλαδή το προηγούμενο και το επόμενο φώνημα. Αυτή η προσέγγιση επιτρέπει στο μοντέλο να συλλάβει φαινόμενα συνάρθρωσης.
\end{enumerate}

Στα μοντέλα GMM-HMM, τα Κρυφά Μαρκοβιανά Μοντέλα χρησιμοποιούνται για να μοντελοποιήσουν τη χρονική δομή και εξέλιξη των φωνημάτων, ενώ τα Μείγματα Γκαουσιανών Κατανομών χρησιμοποιούνται για να μοντελοποιήσουν την κατανομή των ακουστικών χαρακτηριστικών σε κάθε κατάσταση του HMM.

\section{Βήματα Προπαρασκευής}

Η επιτυχής υλοποίηση του συστήματος αναγνώρισης φωνημάτων απαιτούσε μια σειρά από προπαρασκευαστικά βήματα, τα οποία περιγράφονται αναλυτικά παρακάτω:

\subsection{Εγκατάσταση του Kaldi}

Το πρώτο βήμα ήταν η εγκατάσταση του Kaldi στο σύστημά μας, στην περίπωτση μας στο WSL2 με Ubuntu 22.04. Ακολουθήσαμε τις οδηγίες που μας δόθηκαν, οι οποίες περιλάμβαναν:

\begin{enumerate}
    \item Λήψη του Kaldi από το επίσημο repository: \\ 
    \verb|git clone https://github.com/kaldi-asr/kaldi|
    \item Εγκατάσταση των απαραίτητων εξαρτήσεων: \\ 
    \verb|apt install -y zip python2.7 gcc g++ gfortran| κ.λπ.
    \item Ρύθμιση των compilers (ειδικά για Ubuntu 22.04)
    \item Έλεγχος των εξαρτήσεων με το script \verb|extras/check_dependencies.sh|
    \item Μεταγλώττιση των εργαλείων του Kaldi: \verb|make -j 4|
    \item Εγκατάσταση του IRSTLM: \verb|extras/install_irstlm.sh|
    \item Εγκατάσταση του OpenBLAS: \verb|extras/install_openblas.sh|
    \item Ρύθμιση και μεταγλώττιση του κώδικα πηγής του Kaldi
\end{enumerate}

Κατά τη διάρκεια της εγκατάστασης αντιμετωπίσαμε ορισμένες προκλήσεις με τις εκδόσεις των compilers και τις εξαρτήσεις, αλλά αυτές επιλύθηκαν ακολουθώντας τις ειδικές οδηγίες για το εκάστοτε λειτουργικό σύστημα.

\subsection{Λήψη και Προετοιμασία Δεδομένων}

Κατεβάσαμε τα δεδομένα από τον παρεχόμενο σύνδεσμο, τα οποία περιλάμβαναν:

\begin{itemize}
    \item Ηχογραφήσεις από 4 ομιλητές: m1, m3 (άνδρες) και f1, f5 (γυναίκες)
    \item 460 προτάσεις ανά ομιλητή (εκτός από τον m1, όπου έλειπαν οι προτάσεις 231-235)
    \item Αρχείο \verb|transcription.txt| με το κείμενο που εκφωνείται σε κάθε πρόταση
    \item Φάκελο \verb|filesets| με πληροφορίες για τα σύνολα εκπαίδευσης, επαλήθευσης και αποτίμησης
    \item Λεξικό \verb|lexicon.txt| για τη μετατροπή λέξεων σε ακολουθίες φωνημάτων
\end{itemize}

\subsection{Κατασκευή Αρχικού Σκελετού}

Το τελευταίο βήμα της προπαρασκευής ήταν η δημιουργία της κατάλληλης δομής καταλόγων και αρχείων για το Kaldi:

\begin{enumerate}
    \item Δημιουργήσαμε το φάκελο \verb|egs/usc| για την υλοποίησή μας
    
    \item Δημιουργήσαμε τους φακέλους \verb|data/train|, \verb|data/dev|, \verb|data/test| για τα σύνολα δεδομένων
    
    \item Για κάθε σύνολο δεδομένων, δημιουργήσαμε τα εξής αρχεία:
    \begin{itemize}
        \item \textbf{uttids}: Περιέχει τα μοναδικά αναγνωριστικά των εκφωνήσεων
        \item \textbf{utt2spk}: Αντιστοιχίζει κάθε εκφώνηση στον ομιλητή της
        \item \textbf{wav.scp}: Περιέχει τις διαδρομές προς τα αρχεία ήχου
        \item \textbf{text}: Περιέχει τις φωνημικές μεταγραφές των εκφωνήσεων
    \end{itemize}
    
    \item Μετατρέψαμε τα κείμενα σε ακολουθίες φωνημάτων, ακολουθώντας τους εξής κανόνες:
    \begin{itemize}
        \item Μετατροπή όλων των χαρακτήρων σε πεζούς
        \item Αφαίρεση ειδικών χαρακτήρων (εκτός από αποστρόφους)
        \item Προσθήκη του φωνήματος σιωπής "sil" στην αρχή και το τέλος κάθε ακολουθίας
    \end{itemize}
    
    \item Επιπλέον, δημιουργήσαμε τους φακέλους \verb|data/lang|, \verb|data/local/dict|, \verb|data/local/lm_tmp|, και \verb|data/local/nist_lm|, οι οποίοι θα χρησιμοποιούνταν στα επόμενα στάδια της διαδικασίας
\end{enumerate}

Για την αυτοματοποίηση αυτών των βημάτων, αναπτύξαμε scripts σε Python και Bash. Συγκεκριμένα, δημιουργήσαμε το \verb|setup_usc.sh| για την αρχική ρύθμιση του περιβάλλοντος, το \verb|prepare_data.py| για την επεξεργασία των δεδομένων, και το \verb|prepare_usc_data.sh| για την ταξινόμηση και οργάνωση των αρχείων.

\section{Βήματα Κυρίως Μέρους}

\subsection{Προετοιμασία διαδικασίας αναγνώρισης φωνής για τη USC-TIMIT}

Αφού ολοκληρώσαμε τα βήματα προπαρασκευής, προχωρήσαμε στην προετοιμασία της διαδικασίας αναγνώρισης φωνής για τα δεδομένα USC-TIMIT. Ακολουθήσαμε τα εξής βήματα:

\begin{enumerate}
    \item Από τη διαδικασία για τη Wall Street Journal (WSJ) που βρίσκεται στο φάκελο \verb|egs| του Kaldi, πήραμε τα αρχεία \verb|path.sh| και \verb|cmd.sh|. Στο αρχείο \verb|path.sh| θέσαμε τη μεταβλητή \verb|KALDI_ROOT| στη διαδρομή όπου είχαμε εγκαταστήσει το Kaldi. Το αρχείο αυτό το κάναμε source στην αρχή κάθε bash script μας, ώστε να έχουμε διαθέσιμες όλες τις εντολές του Kaldi. Επιπλέον, στο αρχείο \verb|cmd.sh| αλλάξαμε τις τιμές των μεταβλητών \verb|train_cmd|, \verb|decode_cmd| και \verb|cuda_cmd| σε \verb|run.pl|.
    
    \item Δημιουργήσαμε συμβολικούς συνδέσμους (soft links) μέσα στο φάκελο της δικής μας διαδικασίας με ονόματα \verb|steps| και \verb|utils|, τα οποία έδειχναν στους αντίστοιχους φακέλους της WSJ.
    
    \item Δημιουργήσαμε το φάκελο \verb|local| και μέσα σε αυτόν έναν συμβολικό σύνδεσμο με όνομα \verb|score.sh| που έδειχνε στο αρχείο \verb|score_kaldi.sh| που βρίσκεται μέσα στο φάκελο \verb|steps|.
    
    \item Δημιουργήσαμε το φάκελο \verb|conf| και μέσα σε αυτόν τοποθετήσαμε το αρχείο \verb|mfcc.conf| με τις κατάλληλες ρυθμίσεις για την εξαγωγή των MFCC χαρακτηριστικών. Συγκεκριμένα, ρυθμίσαμε τις παραμέτρους \verb|--use-energy=false| και \verb|--sample-frequency=16000|. Ωστόσο, αργότερα χρειάστηκε να προσθέσουμε την παράμετρο \verb|--allow-downsample=true| καθώς τα αρχεία ήχου είχαν συχνότητα δειγματοληψίας 22050 Hz.
    
    \item Τέλος, δημιουργήσαμε τους εξής φακέλους: \verb|data/lang|, \verb|data/local/dict|, \verb|data/local/lm_tmp|, \verb|data/local/nist_lm|, οι οποίοι θα χρησιμοποιούνταν στα επόμενα βήματα της διαδικασίας.
\end{enumerate}

Για την αυτοματοποίηση αυτών των βημάτων, αναπτύξαμε το script \verb|setup_usc.sh|, το οποίο αναλάμβανε την αρχική ρύθμιση του περιβάλλοντος, τη δημιουργία των απαραίτητων φακέλων και την προετοιμασία των αρχείων ρυθμίσεων.

\subsection{Προετοιμασία γλωσσικού μοντέλου}

Στη συνέχεια, προχωρήσαμε στην προετοιμασία του γλωσσικού μοντέλου ακολουθώντας τα παρακάτω βήματα:

\begin{enumerate}
    \item Μέσα στο φάκελο \verb|data/local/dict| αποθηκεύσαμε τα βασικά αρχεία που θα χρησίμευαν για τη δημιουργία του γλωσσικού μοντέλου:
    \begin{itemize}
        \item Τα αρχεία \verb|silence_phones.txt| και \verb|optional_silence.txt| που περιείχαν μόνο το φώνημα της σιωπής (sil).
        \item Το αρχείο \verb|nonsilence_phones.txt| που περιείχε όλα τα υπόλοιπα φωνήματα, ένα σε κάθε γραμμή και ταξινομημένα.
        \item Το αρχείο \verb|lexicon.txt| που αποτελούσε το λεξικό του γλωσσικού μοντέλου. Επειδή ασχοληθήκαμε με αναγνώριση φωνημάτων και όχι λέξεων, το λεξικό ήταν μια 1-1 αντιστοιχία των φωνημάτων με τον εαυτό τους. Σε κάθε γραμμή του περιείχε ένα φώνημα, ακολουθούμενο από ένα κενό και το ίδιο φώνημα ξανά, συμπεριλαμβανομένου και του φωνήματος της σιωπής.
        \item Τα αρχεία \verb|lm_train.text|, \verb|lm_dev.text|, και \verb|lm_test.text|, τα οποία δημιουργήθηκαν από τα αντίστοιχα αρχεία \verb|text| προσθέτοντας τις ειδικές μονάδες <s> και </s> στην αρχή και το τέλος κάθε πρότασης αντίστοιχα.
        \item Το αρχείο \verb|extra_questions.txt|, το οποίο ήταν κενό.
    \end{itemize}
    
    \item Μέσα στο φάκελο \verb|data/local/lm_tmp| δημιουργήσαμε την ενδιάμεση μορφή του γλωσσικού μοντέλου χρησιμοποιώντας την εντολή \verb|build-lm.sh| του πακέτου IRSTLM που είχε εγκατασταθεί μαζί με το Kaldi:
    
    \begin{lstlisting}
    build-lm.sh -i data/local/dict/lm_train.text 
                -n 1 
                -o data/local/lm_tmp/lm_phone_ug.ilm.gz
    
    build-lm.sh -i data/local/dict/lm_train.text 
                -n 2 
                -o data/local/lm_tmp/lm_phone_bg.ilm.gz
    \end{lstlisting}
    
    Δημιουργήσαμε τόσο unigram όσο και bigram μοντέλα, θέτοντας την παράμετρο \verb|-n| σε 1 και 2 αντίστοιχα.
    
    \item Στο φάκελο \verb|data/local/nist_lm| αποθηκεύσαμε το compiled γλωσσικό μοντέλο σε μορφή ARPA, χρησιμοποιώντας την εντολή \verb|compile-lm|:

    \begin{lstlisting}
    compile-lm data/local/lm_tmp/lm_phone_ug.ilm.gz -t=yes /dev/stdout | \
        grep -v unk | gzip -c > data/local/nist_lm/lm_phone_ug.arpa.gz
    compile-lm data/local/lm_tmp/lm_phone_bg.ilm.gz -t=yes /dev/stdout | \
        grep -v unk | gzip -c > data/local/nist_lm/lm_phone_bg.arpa.gz
    \end{lstlisting}
        
    Το unigram μοντέλο ονομάστηκε \verb|lm_phone_ug.arpa.gz| ενώ το bigram \verb|lm_phone_bg.arpa.gz|.
    
    \item Στο φάκελο \verb|data/lang| δημιουργήσαμε το FST του λεξικού της γλώσσας (L.fst) χρησιμοποιώντας την εντολή \verb|prepare_lang.sh| του Kaldi:
    
    \begin{lstlisting}
    utils/prepare_lang.sh data/local/dict "sil" data/local/lang_tmp data/lang
    \end{lstlisting}
    
    \item Χρησιμοποιήσαμε την εντολή \verb|sort| για να ταξινομήσουμε τα αρχεία \verb|wav.scp|, \verb|text| και \verb|utt2spk| στους φακέλους \verb|data/train|, \verb|data/dev| και \verb|data/test|.
    
    \item Εκτελέσαμε το script \verb|utils/utt2spk_to_spk2utt.pl| για να δημιουργήσουμε το αρχείο \verb|spk2utt| από το \verb|utt2spk| για κάθε σύνολο δεδομένων:
    \begin{lstlisting}
    utils/utt2spk_to_spk2utt.pl data/train/utt2spk > data/train/spk2utt
    utils/utt2spk_to_spk2utt.pl data/dev/utt2spk > data/dev/spk2utt
    utils/utt2spk_to_spk2utt.pl data/test/utt2spk > data/test/spk2utt
    \end{lstlisting}
        
    
    \item Τέλος, δημιουργήσαμε το FST της γραμματικής (G.fst) ακολουθώντας παρόμοια διαδικασία με αυτή του παραδείγματος TIMIT του Kaldi. Χρησιμοποιήσαμε την εντολή \verb|format_lm.sh| για να μετατρέψουμε τα ARPA μοντέλα σε FST:
    \begin{lstlisting}
    utils/format_lm.sh data/lang data/local/nist_lm/lm_phone_ug.arpa.gz \
            data/local/dict/lexicon.txt data/lang_ug
    utils/format_lm.sh data/lang data/local/nist_lm/lm_phone_bg.arpa.gz \
            data/local/dict/lexicon.txt data/lang_bg
    \end{lstlisting}
    Στη συνέχεια, δημιουργήσαμε συμβολικούς συνδέσμους για εύκολη πρόσβαση:
    \begin{lstlisting}
        ln -sf data/lang_ug/G.fst data/lang/G_ug.fst
        ln -sf data/lang_bg/G.fst data/lang/G_bg.fst
    \end{lstlisting}
\end{enumerate}

Για την αυτοματοποίηση αυτών των βημάτων, αναπτύξαμε τα εξής scripts:
\begin{itemize}
    \item \verb|prepare_dict.py| και \verb|prepare_dict.sh| για τη δημιουργία των αρχείων λεξικού
    \item \verb|build_lm.sh| για την κατασκευή των γλωσσικών μοντέλων
    \item \verb|compile_lm.sh| για τη μεταγλώττιση των γλωσσικών μοντέλων σε μορφή ARPA
    \item \verb|format_lm.sh| για τη μορφοποίηση των γλωσσικών μοντέλων και τη δημιουργία των G.fst
    \item \verb|prepare_lang_fst.sh| για τη δημιουργία του FST του λεξικού (L.fst)
    \item \verb|sort_files.sh| για την ταξινόμηση των αρχείων δεδομένων και τη δημιουργία των αρχείων spk2utt
\end{itemize}

\subsubsection*{Ερώτημα 1: Για τα γλωσσικά μοντέλα που δημιουργήσατε υπολογίστε το perplexity στο validation και στο test set. Τι δείχνουν αυτές οι τιμές?}

Υπολογίσαμε το perplexity των γλωσσικών μοντέλων στα σύνολα επαλήθευσης (validation) και αποτίμησης (test) χρησιμοποιώντας το εργαλείο \verb|ngram| του SRILM. Αυτό υλοποιήθηκε στο script \verb|calculate_perplexity.sh|.

Τα αποτελέσματα έδειξαν ότι το bigram γλωσσικό μοντέλο είχε χαμηλότερο perplexity σε σύγκριση με το unigram μοντέλο, τόσο στο validation όσο και στο test set. Συγκεκριμένα:

\begin{table}[h]
\centering
\caption{Τιμές Perplexity των Γλωσσικών Μοντέλων}
\label{tab:perplexity}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Σύνολο Δεδομένων} & \textbf{Unigram Perplexity} & \textbf{Bigram Perplexity} \\
\midrule
Validation (Dev) & 35.13 & 32.47 \\
Test & 34.76 & 31.98 \\
\bottomrule
\end{tabular}
\end{table}

Οι τιμές perplexity αντιπροσωπεύουν το μέσο αριθμό εναλλακτικών επιλογών που "βλέπει" το μοντέλο σε κάθε βήμα πρόβλεψης. Συγκεκριμένα:

\begin{itemize}
    \item Χαμηλότερες τιμές perplexity υποδεικνύουν καλύτερο γλωσσικό μοντέλο, με μεγαλύτερη προβλεπτική ικανότητα.
    \item Το γεγονός ότι το bigram μοντέλο έχει χαμηλότερο perplexity από το unigram είναι αναμενόμενο, καθώς λαμβάνει υπόψη περισσότερο συγκείμενο (το προηγούμενο φώνημα) κατά την πρόβλεψη του επόμενου φωνήματος.
    \item Η σχετικά μικρή διαφορά στο perplexity μεταξύ των δύο μοντέλων (περίπου 8\%) υποδεικνύει ότι το πρόσθετο συγκείμενο που παρέχεται από το bigram μοντέλο προσφέρει περιορισμένη βελτίωση στην προβλεπτική ισχύ, πιθανώς λόγω του περιορισμένου μεγέθους του συνόλου δεδομένων εκπαίδευσης.
    \item Οι παρόμοιες τιμές perplexity μεταξύ των συνόλων validation και test υποδεικνύουν ότι τα δύο σύνολα έχουν παρόμοια χαρακτηριστικά και ότι τα γλωσσικά μοντέλα γενικεύουν καλά.
\end{itemize}

Συνολικά, οι τιμές perplexity δείχνουν ότι τα γλωσσικά μοντέλα που δημιουργήσαμε έχουν καλή προβλεπτική ικανότητα για ακολουθίες φωνημάτων, με το bigram μοντέλο να προσφέρει κάποια βελτίωση έναντι του unigram. Ωστόσο, όπως θα δούμε στη συνέχεια της αναφοράς, αυτή η βελτίωση δεν μεταφράζεται πάντα σε αντίστοιχη βελτίωση στην απόδοση του συνολικού συστήματος αναγνώρισης φωνημάτων.

\subsection{Εξαγωγή ακουστικών χαρακτηριστικών}

Για την εξαγωγή των ακουστικών χαρακτηριστικών από τα σήματα ομιλίας, χρησιμοποιήσαμε τα εργαλεία του Kaldi για τον υπολογισμό των Mel-Frequency Cepstral Coefficients (MFCCs) για όλα τα σύνολα δεδομένων (train, dev, test). Συγκεκριμένα, ακολουθήσαμε τα εξής βήματα:

\begin{enumerate}
    \item Αρχικά, δημιουργήσαμε το αρχείο \verb|mfcc.conf| με τις κατάλληλες ρυθμίσεις \cite{slp_ntua_mfcc}:
    \begin{lstlisting}
    --use-energy=false
    --sample-frequency=22050
    \end{lstlisting}
    
    \item Στη συνέχεια, χρησιμοποιήσαμε το script \verb|make_mfcc.sh| του Kaldi για την εξαγωγή των MFCCs από τα αρχεία ήχου:
    \begin{lstlisting}
    steps/make_mfcc.sh --nj 1 --cmd "run.pl" \
        data/train exp/make_mfcc/train data/train/mfcc
        
    steps/make_mfcc.sh --nj 1 --cmd "run.pl" \
        data/dev exp/make_mfcc/dev data/dev/mfcc
        
    steps/make_mfcc.sh --nj 1 --cmd "run.pl" \
        data/test exp/make_mfcc/test data/test/mfcc
    \end{lstlisting}
    
    \item Τέλος, υπολογίσαμε τα στατιστικά CMVN (Cepstral Mean and Variance Normalization) χρησιμοποιώντας το script \verb|compute_cmvn_stats.sh|:
    \begin{lstlisting}
    steps/compute_cmvn_stats.sh \
        data/train exp/make_mfcc/train data/train/mfcc
        
    steps/compute_cmvn_stats.sh \
        data/dev exp/make_mfcc/dev data/dev/mfcc
        
    steps/compute_cmvn_stats.sh \
        data/test exp/make_mfcc/test data/test/mfcc
    \end{lstlisting}
\end{enumerate}

Αυτές οι εντολές δημιούργησαν τα αρχεία \verb|feats.scp| και \verb|cmvn.scp| σε κάθε σύνολο δεδομένων, τα οποία περιέχουν τις διαδρομές προς τα εξαγόμενα χαρακτηριστικά και τα στατιστικά κανονικοποίησης αντίστοιχα.

\subsubsection*{Ερώτημα 2: Με τη δεύτερη εντολή πραγματοποιείται το λεγόμενο Cepstral Mean and Variance Normalization. Τι σκοπό εξυπηρετεί?}

Το Cepstral Mean and Variance Normalization (CMVN) είναι μια τεχνική που χρησιμοποιείται στην επεξεργασία φωνητικών σημάτων για την κανονικοποίηση των ακουστικών χαρακτηριστικών. Ο κύριος σκοπός της είναι να μειώσει τις επιδράσεις διαφορετικών συνθηκών ηχογράφησης, διαφορών μεταξύ των ομιλητών και περιβαλλοντικών θορύβων.

Συγκεκριμένα, το CMVN εξυπηρετεί τους εξής σκοπούς:

\begin{enumerate}
    \item \textbf{Μείωση των επιδράσεων του καναλιού}: Διαφορετικά μικρόφωνα και περιβάλλοντα ηχογράφησης εισάγουν συστηματικές παραμορφώσεις στο σήμα ομιλίας. Το CMVN βοηθά στην εξάλειψη αυτών των επιδράσεων.
    
    \item \textbf{Κανονικοποίηση χαρακτηριστικών ομιλητή}: Διαφορετικοί ομιλητές έχουν διαφορετικά χαρακτηριστικά φωνητικού σωλήνα, τα οποία οδηγούν σε συστηματικές διαφορές στα ακουστικά χαρακτηριστικά τους. Το CMVN μειώνει αυτές τις εξαρτήσεις από τον ομιλητή.
    
    \item \textbf{Βελτίωση της απόδοσης αναγνώρισης}: Κανονικοποιώντας τα χαρακτηριστικά, το CMVN καθιστά πιο αποτελεσματική την εκπαίδευση των μοντέλων αναγνώρισης ομιλίας, καθώς μειώνει τη μεταβλητότητα των δεδομένων εισόδου.
    
    \item \textbf{Ανθεκτικότητα σε θόρυβο}: Ο θόρυβος περιβάλλοντος μπορεί να επηρεάσει διαφορετικά τα διάφορα φασματικά συστατικά του σήματος. Το CMVN μπορεί να βοηθήσει στη μείωση αυτής της επίδρασης.
\end{enumerate}

\textbf{Μαθηματική τεκμηρίωση:}
Το CMVN εφαρμόζει μια γραμμική μετατροπή στα χαρακτηριστικά ώστε να έχουν μηδενικό μέσο και μοναδιαία διακύμανση. Για κάθε διάσταση χαρακτηριστικών $i$ και για κάθε πλαίσιο $t$ σε μια εκφώνηση, το CMVN εκτελεί:

\begin{equation}
\hat{x}_t[i] = \frac{x_t[i] - \mu[i]}{\sigma[i]}
\end{equation}

όπου:
\begin{itemize}
    \item $x_t[i]$ είναι η αρχική τιμή του χαρακτηριστικού
    \item $\hat{x}_t[i]$ είναι η κανονικοποιημένη τιμή
    \item $\mu[i]$ είναι ο μέσος της διάστασης $i$ για όλα τα πλαίσια
    \item $\sigma[i]$ είναι η τυπική απόκλιση της διάστασης $i$ για όλα τα πλαίσια
\end{itemize}

Ο μέσος και η διακύμανση υπολογίζονται ως:
\begin{equation}
\mu[i] = \frac{1}{T} \sum_{t=1}^{T} x_t[i]
\end{equation}
\begin{equation}
\sigma^2[i] = \frac{1}{T} \sum_{t=1}^{T} (x_t[i] - \mu[i])^2
\end{equation}

όπου $T$ είναι ο συνολικός αριθμός πλαισίων στην εκφώνηση ή στον ομιλητή.

Στο Kaldi, το CMVN μπορεί να εφαρμοστεί ανά εκφώνηση (utterance-wise) ή ανά ομιλητή (speaker-wise). Η κανονικοποίηση ανά ομιλητή είναι συνήθως προτιμότερη καθώς παρέχει καλύτερες εκτιμήσεις του μέσου και της διακύμανσης όταν οι εκφωνήσεις είναι σύντομες.

\subsubsection*{Ερώτημα 3: Πόσα ακουστικά frames εξήχθησαν για κάθε μία από τις 5 πρώτες προτάσεις του training set? Τι διάσταση έχουν τα χαρακτηριστικά?}

Για τις πρώτες 5 προτάσεις του training set, εξήχθησαν τα εξής ακουστικά frames:

\begin{table}[h]
\centering
\caption{Αριθμός Ακουστικών Frames για τις Πρώτες 5 Προτάσεις του Training Set}
\label{tab:frames}
\begin{tabular}{@{}lc@{}}
\toprule
\textbf{Πρόταση} & \textbf{Αριθμός Frames} \\
\midrule
f1\_003 & 212 \\
f1\_004 & 249 \\
f1\_005 & 267 \\
f1\_007 & 221 \\
f1\_008 & 184 \\
\bottomrule
\end{tabular}
\end{table}

Η διάσταση των ακουστικών χαρακτηριστικών είναι 13, που αντιστοιχεί στους 13 συντελεστές MFCC (12 cepstral coefficients συν το συντελεστή ενέργειας). Αυτό επιβεβαιώθηκε με την εντολή `feat-to-dim` του Kaldi, η οποία επέστρεψε 13 για κάθε μία από τις εξαγόμενες προτάσεις.

Οι τιμές αυτές είναι αναμενόμενες δεδομένου ότι χρησιμοποιούμε τις προεπιλεγμένες ρυθμίσεις του Kaldi για την εξαγωγή MFCC χαρακτηριστικών, όπου:
\begin{itemize}
    \item Το μήκος πλαισίου (frame length) είναι 25ms
    \item Η μετατόπιση πλαισίου (frame shift) είναι 10ms
    \item Ο αριθμός των συντελεστών MFCC είναι 13
\end{itemize}

Ο διαφορετικός αριθμός frames για κάθε πρόταση οφείλεται στις διαφορετικές διάρκειες των ηχογραφήσεων.

\subsection{Εκπαίδευση ακουστικών μοντέλων και αποκωδικοποίηση προτάσεων}

\subsubsection{Εκπαίδευση μονοφωνικού μοντέλου}

Μετά την εξαγωγή των ακουστικών χαρακτηριστικών, προχωρήσαμε στην εκπαίδευση ενός μονοφωνικού GMM-HMM ακουστικού μοντέλου χρησιμοποιώντας τα δεδομένα εκπαίδευσης. Για το σκοπό αυτό, χρησιμοποιήσαμε το script \verb|train_mono.sh| του Kaldi:

\begin{lstlisting}
steps/train_mono.sh --nj 1 --cmd "run.pl" \
    data/train data/lang exp/mono
\end{lstlisting}

Η εκπαίδευση του μονοφωνικού μοντέλου περιλάμβανε πολλαπλά περάσματα, κατά τη διάρκεια των οποίων το σύστημα εναλλάσσεται μεταξύ ευθυγράμμισης (alignment) των δεδομένων με το τρέχον μοντέλο και επανεκτίμησης των παραμέτρων του μοντέλου με βάση τα νέα ευθυγραμμίσματα.

Μετά την ολοκλήρωση της εκπαίδευσης, το τελικό μοντέλο αποθηκεύτηκε στο φάκελο \verb|exp/mono| και είχε τα εξής χαρακτηριστικά:
\begin{itemize}
    \item Αριθμός φωνημάτων: 165
    \item Αριθμός PDFs (Probability Density Functions): 125
    \item Αριθμός καταστάσεων μετάβασης (transition-states): 505
    \item Διάσταση χαρακτηριστικών: 39 (13 βασικοί συντελεστές MFCC + 13 delta + 13 delta-delta)
    \item Αριθμός Γκαουσιανών: 998
\end{itemize}

\subsubsection{Δημιουργία γράφου HCLG}

Στη συνέχεια, δημιουργήσαμε το γράφο HCLG του Kaldi για το μονοφωνικό μοντέλο, τόσο με το unigram όσο και με το bigram γλωσσικό μοντέλο, χρησιμοποιώντας την εντολή \verb|mkgraph.sh|:

\begin{lstlisting}
utils/mkgraph.sh data/lang_ug exp/mono exp/mono/graph_ug
utils/mkgraph.sh data/lang_bg exp/mono exp/mono/graph_bg
\end{lstlisting}

Οι γράφοι HCLG που δημιουργήθηκαν είχαν τα εξής χαρακτηριστικά:
\begin{itemize}
    \item Unigram HCLG: 152 καταστάσεις και 392 τόξα
    \item Bigram HCLG: 874 καταστάσεις και 4288 τόξα
\end{itemize}

Η μεγάλη διαφορά στον αριθμό των καταστάσεων και των τόξων μεταξύ των δύο γράφων αντανακλά την πρόσθετη πληροφορία συγκειμένου που παρέχει το bigram μοντέλο.

\subsubsection{Αποκωδικοποίηση και αξιολόγηση}

Χρησιμοποιήσαμε τον αλγόριθμο Viterbi για την αποκωδικοποίηση των προτάσεων στα σύνολα επαλήθευσης (dev) και αποτίμησης (test), τόσο με το unigram όσο και με το bigram γλωσσικό μοντέλο:

\begin{lstlisting}
steps/decode.sh --nj 1 --cmd "run.pl" \
    exp/mono/graph_ug data/dev exp/mono/decode_ug_dev
    
steps/decode.sh --nj 1 --cmd "run.pl" \
    exp/mono/graph_ug data/test exp/mono/decode_ug_test
    
steps/decode.sh --nj 1 --cmd "run.pl" \
    exp/mono/graph_bg data/dev exp/mono/decode_bg_dev
    
steps/decode.sh --nj 1 --cmd "run.pl" \
    exp/mono/graph_bg data/test exp/mono/decode_bg_test
\end{lstlisting}

Στη συνέχεια, αξιολογήσαμε τα αποτελέσματα της αποκωδικοποίησης χρησιμοποιώντας τη μετρική Phone Error Rate (PER), η οποία υπολογίζεται ως:

\begin{equation}
PER = 100 \cdot \frac{insertions + substitutions + deletions}{total\_phonemes}
\end{equation}

όπου $total\_phonemes$ είναι ο συνολικός αριθμός φωνημάτων στις αναφορές (references).

Τα αποτελέσματα της αξιολόγησης φαίνονται στον παρακάτω πίνακα \ref{tab:mono_per}:

\begin{table}[h!]
\centering
\caption{Phone Error Rate (PER) του Μονοφωνικού Μοντέλου}
\label{tab:mono_per}
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Σύνολο} & \textbf{Γλωσσικό Μοντέλο} & \textbf{PER (\%)} & \textbf{Insertions} & \textbf{Deletions} & \textbf{Substitutions} \\
\midrule
Dev & Unigram & 54.71 & 177 & 1069 & 1343 \\
Dev & Bigram & 54.71 & 177 & 1069 & 1343 \\
Test & Unigram & 52.30 & 253 & 2926 & 3315 \\
Test & Bigram & 52.30 & 253 & 2926 & 3315 \\
\bottomrule
\end{tabular}
\end{table}

Παρατηρούμε ότι δεν υπάρχει διαφορά στην απόδοση μεταξύ του unigram και του bigram γλωσσικού μοντέλου για το μονοφωνικό ακουστικό μοντέλο. Αυτό θα μπορούσε να οφείλεται στο γεγονός ότι το bigram μοντέλο δεν παρέχει σημαντικά περισσότερη διακριτική ικανότητα σε σχέση με το unigram για την αναγνώριση φωνημάτων με το συγκεκριμένο σύνολο δεδομένων.

\textbf{Υπερπαράμετροι της διαδικασίας scoring:}

Οι δύο υπερπαράμετροι της διαδικασίας scoring είναι:

\begin{enumerate}
    \item \textbf{beam\_width (ή 'beam')}: Ελέγχει το εύρος της δέσμης αναζήτησης κατά την αποκωδικοποίηση. Μια μεγαλύτερη τιμή επιτρέπει στον αποκωδικοποιητή να εξερευνήσει περισσότερες υποθέσεις, αυξάνοντας την πιθανότητα εύρεσης καλύτερης λύσης, αλλά με αυξημένο υπολογιστικό κόστος.
    
    \item \textbf{word\_insertion\_penalty (ή 'wip')}: Είναι μια παράμετρος που ελέγχει την ισορροπία μεταξύ προσθέσεων (insertions) και διαγραφών (deletions). Μια υψηλότερη τιμή ποινής προσθήκης λέξεων τείνει να μειώνει τις προσθέσεις αλλά μπορεί να αυξήσει τις διαγραφές.
\end{enumerate}

Στο καλύτερο μονοφωνικό μοντέλο μας, οι τιμές αυτών των υπερπαραμέτρων ήταν:
\begin{itemize}
    \item beam\_width = 7
    \item word\_insertion\_penalty = 0.0
\end{itemize}

Αυτές οι τιμές παρείχαν το βέλτιστο συμβιβασμό μεταξύ προσθέσεων, διαγραφών και αντικαταστάσεων.

\subsubsection{Εκπαίδευση τριφωνικού μοντέλου}

Για να βελτιώσουμε την απόδοση του συστήματος, προχωρήσαμε στην εκπαίδευση ενός τριφωνικού GMM-HMM μοντέλου. Η διαδικασία αυτή πραγματοποιήθηκε σε δύο βήματα:

\begin{enumerate}
    \item Πρώτα, πραγματοποιήσαμε ευθυγράμμιση (alignment) των φωνημάτων χρησιμοποιώντας το μονοφωνικό μοντέλο:
    \begin{lstlisting}
    steps/align_si.sh --nj 1 --cmd "run.pl" \
        data/train data/lang exp/mono exp/mono_ali
    \end{lstlisting}
    
    \item Στη συνέχεια, χρησιμοποιήσαμε αυτά τα ευθυγραμμίσματα για την εκπαίδευση του τριφωνικού μοντέλου:
    \begin{lstlisting}
    steps/train_deltas.sh --cmd "run.pl" \
        2500 15000 data/train data/lang exp/mono_ali exp/tri1
    \end{lstlisting}
    όπου οι παράμετροι 2500 και 15000 αντιστοιχούν στον αριθμό των καταστάσεων και τον αριθμό των Γκαουσιανών αντίστοιχα.
\end{enumerate}

Μετά την εκπαίδευση του τριφωνικού μοντέλου, δημιουργήσαμε τους γράφους HCLG για το unigram και το bigram γλωσσικό μοντέλο, και αποκωδικοποιήσαμε τα σύνολα dev και test. Τα αποτελέσματα της αξιολόγησης για το τριφωνικό μοντέλο είναι τα εξής:

\begin{table}[h]
\centering
\caption{Phone Error Rate (PER) του Τριφωνικού Μοντέλου}
\label{tab:tri_per}
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Σύνολο} & \textbf{Γλωσσικό Μοντέλο} & \textbf{PER (\%)} & \textbf{Insertions} & \textbf{Deletions} & \textbf{Substitutions} \\
\midrule
Dev & Unigram & 46.98 & 228 & 786 & 1209 \\
Dev & Bigram & 46.98 & 228 & 786 & 1209 \\
Test & Unigram & 44.21 & 496 & 1837 & 3156 \\
Test & Bigram & 44.21 & 496 & 1837 & 3156 \\
\bottomrule
\end{tabular}
\end{table}

Παρατηρούμε ότι το τριφωνικό μοντέλο πετυχαίνει σημαντικά χαμηλότερο PER σε σχέση με το μονοφωνικό, με βελτίωση περίπου 7.73\% στο σύνολο επαλήθευσης (dev) και 8.09\% στο σύνολο αποτίμησης (test). Και πάλι, δεν παρατηρείται διαφορά στην απόδοση μεταξύ του unigram και του bigram γλωσσικού μοντέλου.

\subsubsection*{Ερώτημα 4: Εξηγήστε τη δομή ενός ακουστικού μοντέλου GMM-HMM. Τι σκοπό εξυπηρετούν τα μαρκοβιανά μοντέλα στη συγκεκριμένη περίπτωση και τι τα μίγματα γκαουσιανών? Με ποιό τρόπο γίνεται η εκπαίδευση ενός τέτοιου μοντέλου? Περιγράψτε τη διαδικασία εκπαίδευσης ενός μονοφωνικού μοντέλου.}

Το GMM-HMM (Gaussian Mixture Model - Hidden Markov Model) είναι ένα υβριδικό ακουστικό μοντέλο που συνδυάζει δύο στατιστικά πλαίσια για την αναπαράσταση των φωνητικών μονάδων (φωνημάτων) στην αναγνώριση ομιλίας.

\textbf{Δομή του GMM-HMM:}

Στο GMM-HMM:
\begin{itemize}
    \item Κάθε φώνημα αναπαρίσταται από ένα Κρυφό Μαρκοβιανό Μοντέλο (HMM), συνήθως με 3 καταστάσεις σε μια αριστερά-προς-δεξιά τοπολογία.
    \item Κάθε κατάσταση του HMM συνδέεται με ένα Μείγμα Γκαουσιανών Κατανομών (GMM), το οποίο μοντελοποιεί την κατανομή των ακουστικών χαρακτηριστικών για αυτή την κατάσταση.
    \item Στο μονοφωνικό μοντέλο, κάθε φώνημα μοντελοποιείται ανεξάρτητα από το συγκείμενό του.
    \item Στο τριφωνικό μοντέλο, κάθε φώνημα μοντελοποιείται μαζί με το αριστερό και το δεξί του συγκείμενο (προηγούμενο και επόμενο φώνημα).
\end{itemize}

\textbf{Ρόλος των Κρυφών Μαρκοβιανών Μοντέλων (HMMs):}
\begin{itemize}
    \item Μοντελοποιούν τη χρονική δομή και εξέλιξη των φωνημάτων.
    \item Χειρίζονται τη μεταβλητή διάρκεια των φωνημάτων μέσω των αυτο-μεταβάσεων (self-transitions).
    \item Αναπαριστούν την ακολουθιακή φύση της ομιλίας μέσω των πιθανοτήτων μετάβασης.
    \item Επιτρέπουν την αποδοτική αποκωδικοποίηση με χρήση δυναμικού προγραμματισμού (αλγόριθμος Viterbi).
\end{itemize}

\textbf{Ρόλος των Μειγμάτων Γκαουσιανών Κατανομών (GMMs):}
\begin{itemize}
    \item Μοντελοποιούν την κατανομή των ακουστικών χαρακτηριστικών για κάθε κατάσταση του HMM.
    \item Έχουν τη δυνατότητα να αναπαραστήσουν πολύπλοκες, πολυτροπικές κατανομές χρησιμοποιώντας πολλαπλές Γκαουσιανές συνιστώσες.
    \item Κάθε Γκαουσιανή συνιστώσα έχει ένα βάρος, ένα διάνυσμα μέσων και έναν πίνακα συνδιακύμανσης.
    \item Παρέχουν τις πιθανότητες εκπομπής: $p(acoustic\_feature | state)$.
\end{itemize}

\textbf{Διαδικασία εκπαίδευσης ενός GMM-HMM μοντέλου:}

Η εκπαίδευση ενός GMM-HMM μοντέλου πραγματοποιείται με χρήση του αλγορίθμου Baum-Welch, ο οποίος είναι μια ειδική περίπτωση του αλγορίθμου Expectation-Maximization (EM) για HMMs:

\begin{enumerate}
    \item \textbf{Αρχικοποίηση}: Ξεκινάμε με ένα αρχικό μοντέλο, συνήθως με flat-start (ομοιόμορφες πιθανότητες).
    
    \item \textbf{Επανεκτίμηση} (Baum-Welch algorithm):
    \begin{itemize}
        \item E-step: Υπολογίζουμε τις πιθανότητες κατάληψης καταστάσεων (state occupancy probabilities) δεδομένων των τρεχουσών παραμέτρων του μοντέλου.
        \item M-step: Ενημερώνουμε τις παραμέτρους του μοντέλου ώστε να μεγιστοποιήσουμε την πιθανοφάνεια των δεδομένων.
    \end{itemize}
    
    \item \textbf{Επαυξητική βελτίωση}: Σταδιακά αυξάνουμε την πολυπλοκότητα του μοντέλου:
    \begin{itemize}
        \item Αυξάνουμε τον αριθμό των Γκαουσιανών συνιστωσών ανά κατάσταση.
        \item Διαιρούμε υπάρχουσες Γκαουσιανές και επανεκτιμούμε τις παραμέτρους.
    \end{itemize}
\end{enumerate}

\textbf{Εκπαίδευση ενός μονοφωνικού μοντέλου:}

Η διαδικασία εκπαίδευσης ενός μονοφωνικού μοντέλου, όπως υλοποιείται στο Kaldi, περιλαμβάνει τα εξής βήματα:

\begin{enumerate}
    \item \textbf{Αρχικοποίηση} (Flat start): Όλα τα φωνήματα αρχικοποιούνται με την ίδια Γκαουσιανή κατανομή, συνήθως με μέση τιμή 0 και μοναδιαία διακύμανση.
    
    \item \textbf{Ευθυγράμμιση και επανεκτίμηση}: Επαναληπτική διαδικασία όπου:
    \begin{itemize}
        \item Ευθυγραμμίζουμε τα δεδομένα με το τρέχον μοντέλο χρησιμοποιώντας τον αλγόριθμο Viterbi.
        \item Επανεκτιμούμε τις παραμέτρους του μοντέλου με βάση αυτά τα ευθυγραμμίσματα.
    \end{itemize}
    
    \item \textbf{Διάσπαση Γκαουσιανών}: Καθώς το μοντέλο βελτιώνεται, αυξάνουμε σταδιακά τον αριθμό των Γκαουσιανών συνιστωσών ανά κατάσταση, διασπώντας τις υπάρχουσες συνιστώσες και επανεκτιμώντας τις παραμέτρους.
    
    \item \textbf{Σύγκλιση}: Η διαδικασία συνεχίζεται μέχρι να επιτευχθεί σύγκλιση, δηλαδή μέχρι η βελτίωση της πιθανοφάνειας μεταξύ διαδοχικών επαναλήψεων να γίνει αμελητέα.
\end{enumerate}

Στο Kaldi, η εκπαίδευση του μονοφωνικού μοντέλου περιλαμβάνει συνήθως 30-40 περάσματα, κατά τη διάρκεια των οποίων αυξάνεται σταδιακά ο αριθμός των Γκαουσιανών, ενώ οι πιθανότητες μετάβασης του HMM επανεκτιμώνται επίσης.

\subsubsection*{Ερώτημα 5: Γράψτε πώς υπολογίζεται η a posteriori πιθανότητα σύμφωνα με τον τύπο του Bayes για το πρόβλημα της αναγνώρισης φωνής. Συγκεκριμένα, πώς βρίσκεται η πιο πιθανή λέξη (ή φώνημα στην περίπτωσή μας) δεδομένης μίας ακολουθίας ακουστικών χαρακτηριστικών?}

Στην αναγνώριση ομιλίας, ο στόχος είναι να βρούμε την πιο πιθανή ακολουθία λέξεων (ή φωνημάτων) δεδομένων των ακουστικών παρατηρήσεων. Αυτό εκφράζεται χρησιμοποιώντας το θεώρημα του Bayes ως εξής:

\begin{equation}
W^* = \underset{W}{\text{argmax}} \, P(W|O) = \underset{W}{\text{argmax}} \, \frac{P(O|W) \times P(W)}{P(O)}
\end{equation}

όπου:
\begin{itemize}
    \item $W^*$ είναι η πιο πιθανή ακολουθία λέξεων/φωνημάτων
    \item $O$ είναι η ακολουθία των ακουστικών παρατηρήσεων (χαρακτηριστικά MFCC)
    \item $P(W|O)$ είναι η εκ των υστέρων (a posteriori) πιθανότητα που θέλουμε να μεγιστοποιήσουμε
    \item $P(O|W)$ είναι η πιθανότητα του ακουστικού μοντέλου (likelihood των παρατηρήσεων δεδομένων των λέξεων)
    \item $P(W)$ είναι η εκ των προτέρων (a priori) πιθανότητα από το γλωσσικό μοντέλο
    \item $P(O)$ είναι η πιθανότητα των παρατηρήσεων (σταθερή για όλες τις $W$, οπότε μπορεί να αγνοηθεί)
\end{itemize}

Απλοποιώντας, έχουμε:
\begin{equation}
W^* = \underset{W}{\text{argmax}} \, P(O|W) \times P(W)
\end{equation}

Για την αναγνώριση φωνημάτων, ο υπολογισμός της a posteriori πιθανότητας αναλύεται ως εξής:

\begin{enumerate}
    \item \textbf{Ακουστικό μοντέλο $P(O|W)$}:
    \begin{itemize}
        \item Υπολογίζεται χρησιμοποιώντας το GMM-HMM μοντέλο.
        \item Το HMM παρέχει την πιθανότητα της ακολουθίας καταστάσεων.
        \item Το GMM παρέχει την πιθανότητα των παρατηρήσεων δεδομένης κάθε κατάστασης.
        \item Για μια ακολουθία ακουστικών παρατηρήσεων $O = (o_1, o_2, \ldots, o_T)$ και μια ακολουθία καταστάσεων $S = (s_1, s_2, \ldots, s_T)$, υπολογίζουμε:
        \begin{equation}
        P(O|W) = \sum_{S} P(O|S,W) \times P(S|W)
        \end{equation}
        Όπου $P(O|S,W)$ δίνεται από το GMM και $P(S|W)$ από τις πιθανότητες μετάβασης του HMM.
    \end{itemize}
    
    \item \textbf{Γλωσσικό μοντέλο $P(W)$}:
    \begin{itemize}
        \item Παρέχει την εκ των προτέρων πιθανότητα της ακολουθίας φωνημάτων.
        \item Στην περίπτωση του unigram μοντέλου: $P(W) = \prod_{i=1}^{n} P(w_i)$
        \item Στην περίπτωση του bigram μοντέλου: $P(W) = \prod_{i=1}^{n} P(w_i|w_{i-1})$
    \end{itemize}
    
    \item \textbf{Αποκωδικοποίηση}:
    \begin{itemize}
        \item Ο αλγόριθμος Viterbi χρησιμοποιείται για την αποδοτική εύρεση της πιο πιθανής ακολουθίας.
        \item Ο Viterbi αποφεύγει τον αναλυτικό υπολογισμό όλων των πιθανών ακολουθιών φωνημάτων με τη χρήση δυναμικού προγραμματισμού.
        \item Υπολογίζει την πιθανότητα του καλύτερου μονοπατιού προς κάθε κατάσταση σε κάθε χρονικό βήμα.
        \item Διατηρεί το μονοπάτι που οδήγησε σε αυτή την καλύτερη πιθανότητα.
        \item Τέλος, εντοπίζει την πιο πιθανή ακολουθία με οπισθοδρόμηση (backtracking).
    \end{itemize}
\end{enumerate}

Στο Kaldi, αυτή η διαδικασία υλοποιείται μέσω του γράφου HCLG, ο οποίος συνδυάζει όλες τις απαραίτητες πληροφορίες για την αποδοτική αποκωδικοποίηση. Ο αλγόριθμος αποκωδικοποίησης αναζητά το βέλτιστο μονοπάτι μέσω αυτού του γράφου, μεγιστοποιώντας το γινόμενο των πιθανοτήτων του ακουστικού και του γλωσσικού μοντέλου.

\subsubsection*{Ερώτημα 6: Εξηγήστε τη δομή του γράφου HCLG του Kaldi περιγραφικά.}

Ο γράφος HCLG του Kaldi είναι ένας σταθμισμένος πεπερασμένος μετατροπέας καταστάσεων (Weighted Finite State Transducer - WFST) που συνδυάζει τέσσερις διαφορετικούς μετατροπείς σε ένα βελτιστοποιημένο δίκτυο αναζήτησης. Το όνομα HCLG προέρχεται από τη σύνθεση των τεσσάρων συστατικών μετατροπέων:

\begin{enumerate}
    \item \textbf{H: Ο μετατροπέας HMM (HMM transducer)}
    \begin{itemize}
        \item Αναπαριστά την τοπολογία του HMM για κάθε εξαρτώμενο από το συγκείμενο φώνημα (context-dependent phone).
        \item Απεικονίζει από αναγνωριστικά μετάβασης (transition-ids) σε εξαρτώμενα από το συγκείμενο φωνήματα (pdf-ids).
        \item Κωδικοποιεί τις αυτο-μεταβάσεις (self-loops) και τις μεταβάσεις μεταξύ καταστάσεων.
    \end{itemize}
    
    \item \textbf{C: Ο μετατροπέας εξάρτησης από το συγκείμενο (Context-dependency transducer)}
    \begin{itemize}
        \item Απεικονίζει από εξαρτώμενα από το συγκείμενο φωνήματα σε ανεξάρτητα από το συγκείμενο φωνήματα.
        \item Για τρίφωνα, απεικονίζει ένα φώνημα στο συγκείμενό του (π.χ., a-b+c) στο βασικό φώνημα (b).
        \item Χειρίζεται την κοινή χρήση παραμέτρων μέσω δέντρων φωνητικών αποφάσεων.
    \end{itemize}
    
    \item \textbf{L: Ο μετατροπέας λεξικού (Lexicon transducer)}
    \begin{itemize}
        \item Απεικονίζει από λέξεις σε φωνήματα.
        \item Ενσωματώνει παραλλαγές προφοράς.
        \item Περιλαμβάνει ειδικά σύμβολα για το χειρισμό της σιωπής και των ορίων λέξεων.
    \end{itemize}
    
    \item \textbf{G: Ο μετατροπέας γραμματικής (Grammar transducer)}
    \begin{itemize}
        \item Αναπαριστά το γλωσσικό μοντέλο (πιθανότητες n-gram).
        \item Απεικονίζει μεταξύ ακολουθιών λέξεων.
        \item Κωδικοποιεί την πιθανότητα των ακολουθιών λέξεων.
    \end{itemize}
\end{enumerate}

Η σύνθεση αυτών των μετατροπέων ($HCLG = H \circ C \circ L \circ G$) δημιουργεί έναν ενιαίο βελτιστοποιημένο γράφο όπου:
\begin{itemize}
    \item Οι ετικέτες εισόδου είναι τα αναγνωριστικά μετάβασης (transition-ids) από το ακουστικό μοντέλο.
    \item Οι ετικέτες εξόδου είναι οι λέξεις.
    \item Τα βάρη συνδυάζουν τις πιθανότητες του ακουστικού και του γλωσσικού μοντέλου.
\end{itemize}

Αυτός ο ενοποιημένος γράφος επιτρέπει την αποδοτική αποκωδικοποίηση σε ένα πέρασμα, όπου όλοι οι περιορισμοί (ακουστικοί, φωνητικοί, λεξικοί και γραμματικοί) εφαρμόζονται ταυτόχρονα κατά την αναζήτηση. Ο γράφος βελτιστοποιείται μέσω πράξεων όπως ο προσδιορισμός (determinization), η ελαχιστοποίηση (minimization) και η ώθηση βάρους (weight pushing) για να γίνει η αποκωδικοποίηση ταχύτερη και πιο αποδοτική.

Κατά την αποκωδικοποίηση, το Kaldi χρησιμοποιεί έναν αλγόριθμο μετάδοσης συμβόλων (token-passing algorithm) σε αυτόν το γράφο για να βρει την πιο πιθανή ακολουθία λέξεων δεδομένων των ακουστικών παρατηρήσεων.

\section{Υλοποίηση και Οργάνωση Κώδικα}

Για την υλοποίηση του συστήματος αναγνώρισης φωνημάτων, αναπτύξαμε μια σειρά από scripts σε Bash και Python. Παρακάτω περιγράφουμε τα κύρια αρχεία που αναπτύξαμε και το σκοπό τους, οργανωμένα ανά λειτουργία.

\subsection{Αρχικοποίηση και Ρύθμιση Περιβάλλοντος}

\begin{itemize}
    \item \textbf{setup\_usc.sh}: Το κύριο script ρύθμισης που δημιουργεί την απαραίτητη δομή καταλόγων, τα αρχεία ρυθμίσεων και τους συμβολικούς συνδέσμους. Καλεί τα scripts προετοιμασίας δεδομένων και λεξικού.
\end{itemize}

\subsection{Προετοιμασία Δεδομένων}

\begin{itemize}
    \item \textbf{prepare\_data.py}: Script Python που επεξεργάζεται τα αρχικά δεδομένα (ηχογραφήσεις και μεταγραφές) και δημιουργεί τα απαραίτητα αρχεία (uttids, utt2spk, wav.scp, text) για το Kaldi.
    
    \item \textbf{prepare\_usc\_data.sh}: Script Bash που καλεί το prepare\_data.py και ταξινομεί τα παραγόμενα αρχεία.
\end{itemize}

\subsection{Προετοιμασία Λεξικού και Γλωσσικού Μοντέλου}

\begin{itemize}
    \item \textbf{prepare\_dict.py}: Script Python που δημιουργεί τα αρχεία λεξικού (silence\_phones.txt, nonsilence\_phones.txt, lexicon.txt, extra\_questions.txt) και τα αρχεία lm\_\*.text.
    
    \item \textbf{prepare\_dict.sh}: Script Bash που καλεί το prepare\_dict.py.
    
    \item \textbf{build\_lm.sh}: Script που δημιουργεί τα unigram και bigram γλωσσικά μοντέλα χρησιμοποιώντας το IRSTLM.
    
    \item \textbf{compile\_lm.sh}: Script που μεταγλωττίζει τα γλωσσικά μοντέλα σε μορφή ARPA.
    
    \item \textbf{format\_lm.sh}: Script που μορφοποιεί τα γλωσσικά μοντέλα και δημιουργεί τα αρχεία G.fst.
    
    \item \textbf{prepare\_lang\_fst.sh}: Script που δημιουργεί το L.fst χρησιμοποιώντας την εντολή prepare\_lang.sh του Kaldi.
\end{itemize}

\subsection{Εξαγωγή Χαρακτηριστικών}

\begin{itemize}
    \item \textbf{fix\_mfcc\_config.sh}: Script που ενημερώνει το αρχείο mfcc.conf με τις σωστές παραμέτρους και εξάγει τα MFCC χαρακτηριστικά από τα αρχεία ήχου.
\end{itemize}

\subsection{Εκπαίδευση Μοντέλων και Αποκωδικοποίηση}

\begin{itemize}
    \item \textbf{train\_mono.sh}: Script που εκπαιδεύει το μονοφωνικό GMM-HMM μοντέλο.
    
    \item \textbf{make\_graphs.sh}: Script που δημιουργεί τους γράφους HCLG για το μονοφωνικό μοντέλο.
    
    \item \textbf{decode\_and\_score.sh}: Script που αποκωδικοποιεί και αξιολογεί τα δεδομένα dev και test με το μονοφωνικό μοντέλο.
    
    \item \textbf{train\_triphone.sh}: Script που ευθυγραμμίζει τα δεδομένα με το μονοφωνικό μοντέλο, εκπαιδεύει το τριφωνικό μοντέλο, δημιουργεί γράφους HCLG, αποκωδικοποιεί και αξιολογεί.
\end{itemize}

\subsection{Βοηθητικά Scripts}

\begin{itemize}
    \item \textbf{cleanup\_and\_regenerate.sh}: Βοηθητικό script που καθαρίζει τα υπάρχοντα αρχεία δεδομένων και τα αναδημιουργεί, χρήσιμο για αντιμετώπιση προβλημάτων.
\end{itemize}

\subsection{Σειρά Εκτέλεσης}

Για την πλήρη υλοποίηση του συστήματος αναγνώρισης φωνημάτων, τα scripts πρέπει να εκτελεστούν με την ακόλουθη σειρά:

\begin{enumerate}
    \item \textbf{setup\_usc.sh}: Ρύθμιση του περιβάλλοντος και βασική προετοιμασία δεδομένων.
    
    \item \textbf{build\_lm.sh}: Δημιουργία των γλωσσικών μοντέλων.
    
    \item \textbf{compile\_lm.sh}: Μεταγλώττιση των γλωσσικών μοντέλων σε μορφή ARPA.
    
    \item \textbf{format\_lm.sh}: Μορφοποίηση των γλωσσικών μοντέλων και δημιουργία των G.fst.
    
    \item \textbf{prepare\_lang\_fst.sh}: Δημιουργία του L.fst.
    
    \item \textbf{fix\_mfcc\_config.sh}: Εξαγωγή των MFCC χαρακτηριστικών.
    
    \item \textbf{train\_mono.sh}: Εκπαίδευση του μονοφωνικού μοντέλου.
    
    \item \textbf{make\_graphs.sh}: Δημιουργία των γράφων HCLG για το μονοφωνικό μοντέλο.
    
    \item \textbf{decode\_and\_score.sh}: Αποκωδικοποίηση και αξιολόγηση με το μονοφωνικό μοντέλο.
    
    \item \textbf{train\_triphone.sh}: Εκπαίδευση, αποκωδικοποίηση και αξιολόγηση με το τριφωνικό μοντέλο.
\end{enumerate}

Αξίζει να σημειωθεί ότι κάποια από τα scripts παραπάνω καλούν αυτόματα άλλα scripts, οπότε δεν είναι απαραίτητο να εκτελεστούν όλα χειροκίνητα. Για παράδειγμα, το script \textbf{setup\_usc.sh} καλεί τα \textbf{prepare\_usc\_data.sh} και \textbf{prepare\_dict.sh}.

%\section{Συμπεράσματα και Μελλοντικές Βελτιώσεις}
%
%Στην παρούσα άσκηση, υλοποιήσαμε ένα σύστημα αναγνώρισης φωνημάτων χρησιμοποιώντας το εργαλείο Kaldi. Εκπαιδεύσαμε τόσο μονοφωνικά όσο και τριφωνικά GMM-HMM μοντέλα και αξιολογήσαμε την απόδοσή τους στην αναγνώριση φωνημάτων από ηχογραφήσεις της USC-TIMIT.
%
%\subsection{Κύρια Συμπεράσματα}
%
%\begin{enumerate}
%    \item Το τριφωνικό μοντέλο παρουσίασε σημαντικά καλύτερη απόδοση σε σχέση με το μονοφωνικό, με βελτίωση περίπου 8\% στο Phone Error Rate (PER). Αυτό επιβεβαιώνει τη σημασία του συγκειμένου στην αναγνώριση φωνημάτων.
%    
%    \item Δεν παρατηρήθηκε διαφορά στην απόδοση μεταξύ του unigram και του bigram γλωσσικού μοντέλου, παρά το γεγονός ότι το bigram μοντέλο είχε χαμηλότερο perplexity. Αυτό θα μπορούσε να οφείλεται στο περιορισμένο μέγεθος του συνόλου δεδομένων εκπαίδευσης.
%    
%    \item Η τεχνική CMVN αποδείχθηκε απαραίτητη για την αντιμετώπιση των διαφορών μεταξύ των ομιλητών και των συνθηκών ηχογράφησης.
%    
%    \item Οι βέλτιστες τιμές των υπερπαραμέτρων της διαδικασίας scoring ήταν beam\_width = 7 και word\_insertion\_penalty = 0.0 για το μονοφωνικό μοντέλο, ενώ για το τριφωνικό μοντέλο η βέλτιστη τιμή του beam\_width ήταν 10 στο σύνολο επαλήθευσης (dev) και 7 στο σύνολο αποτίμησης (test).
%\end{enumerate}
%
%\subsection{Μελλοντικές Βελτιώσεις}
%
%Για τη βελτίωση της απόδοσης του συστήματος αναγνώρισης φωνημάτων, θα μπορούσαμε να εξετάσουμε τις ακόλουθες επεκτάσεις:
%
%\begin{enumerate}
%    \item \textbf{Χρήση πιο προηγμένων ακουστικών μοντέλων}: Αντί για GMM-HMM μοντέλα, θα μπορούσαμε να χρησιμοποιήσουμε πιο προηγμένα μοντέλα όπως Subspace GMM (SGMM) ή νευρωνικά δίκτυα (DNN-HMM), τα οποία έχουν αποδειχθεί πιο αποτελεσματικά στην αναγνώριση ομιλίας.
%    
%    \item \textbf{Εφαρμογή τεχνικών προσαρμογής στον ομιλητή}: Τεχνικές όπως οι Maximum Likelihood Linear Regression (MLLR) και fMLLR (feature-space MLLR) θα μπορούσαν να βελτιώσουν την απόδοση του συστήματος προσαρμόζοντας το μοντέλο στα χαρακτηριστικά κάθε ομιλητή.
%    
%    \item \textbf{Χρήση πιο εξελιγμένων χαρακτηριστικών}: Εκτός από τα βασικά MFCC, θα μπορούσαμε να εξετάσουμε πιο εξελιγμένα χαρακτηριστικά όπως τα i-vectors ή τα bottleneck features από νευρωνικά δίκτυα.
%    
%    \item \textbf{Εμπλουτισμός του συνόλου δεδομένων}: Η αύξηση του μεγέθους του συνόλου δεδομένων εκπαίδευσης με περισσότερες ηχογραφήσεις και ομιλητές θα μπορούσε να βελτιώσει τη γενίκευση του μοντέλου.
%    
%    \item \textbf{Βελτίωση του γλωσσικού μοντέλου}: Θα μπορούσαμε να εξετάσουμε υψηλότερης τάξης n-gram μοντέλα (trigram, 4-gram) ή ακόμα και μοντέλα νευρωνικών δικτύων για να βελτιώσουμε την απόδοση του γλωσσικού μοντέλου.
%    
%    \item \textbf{Βελτιστοποίηση της διαδικασίας αποκωδικοποίησης}: Θα μπορούσαμε να πειραματιστούμε με διαφορετικές τιμές των υπερπαραμέτρων της αποκωδικοποίησης και του scoring για να βρούμε το βέλτιστο συμβιβασμό μεταξύ ακρίβειας και υπολογιστικού κόστους.
%\end{enumerate}
%
%Συνολικά, η εργασία αυτή μας έδωσε την ευκαιρία να εξοικειωθούμε με τις βασικές τεχνικές αναγνώρισης ομιλίας και να κατανοήσουμε τις προκλήσεις και τις δυνατότητες αυτού του πεδίου. Η χρήση του Kaldi μας επέτρεψε να εφαρμόσουμε προηγμένες τεχνικές και να αναπτύξουμε ένα λειτουργικό σύστημα αναγνώρισης φωνημάτων, παρέχοντας μια στέρεη βάση για περαιτέρω έρευνα και ανάπτυξη στο πεδίο της επεξεργασίας ομιλίας.
%
%
%

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}