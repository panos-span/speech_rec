\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[LGR,T1]{fontenc}
\usepackage{alphabeta}
\usepackage{amsmath}
\usepackage{float}
\usepackage{multirow}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{booktabs}  % For better looking tables
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{breakurl}
\usepackage[numbers]{natbib}
\usepackage{subcaption}  % Προσθέστε αυτή τη γραμμή στο preample του εγγράφου

\lstset{
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=\color{blue},
  commentstyle=\color{gray},
  stringstyle=\color{red},
  showstringspaces=false,
  breaklines=true,
  frame=single,
  language=R,
  extendedchars=true,
  literate={β}{{\beta}}1
}

%\title{Αναγνώριση Προτύπων \\ 2η Εργαστηριακή Άσκηση \\ Χειμερινό Εξάμηνο 2024-2025 \\ Ε.ΔE.ΜΜ}
%\author{Σπανάκης Παναγιώτης-Αλέξιος (ΑΜ: 03400274)}
%\date{16/12/2024}

\begin{document}

\begin{titlepage}
    \begin{center}
        \vspace*{1cm}
        
        \Large
        \textbf{ΕΘΝΙΚΟ ΜΕΤΣΟΒΙΟ ΠΟΛΥΤΕΝΧΕΙΟ}
        
        \vspace*{0.5cm}

        \large 
        Δ.Π.Μ.Σ. Ε.ΔΕ.ΜΜ
        \includegraphics{ntua.png}

        \large
        \textbf{\\Επεξεργασία Φωνής και Φυσικής Γλώσσας}
        
        
        
        \vspace{2.5cm}
        \small
        \textit{$1^η$ Εργαστηριακή άσκηση}        
        
        %%% First option %%%

        % \vspace{2.5cm}
        % \large
        % \vfill
        % Σπανάκης Παναγιώτης-Αλέξιος 
        % \\Α.Μ.: 09321011 

        % \vspace{2.5cm}
        % \large
        % \vfill % 
        % Ιωάννης Καραπαρίσης 
        % \\Α.Μ.: 09321011 
    
    \end{center}
    
    %% SECOND OPTION %%%%
    
    \begin{flushright}
        \vfill
        Σπανάκης Παναγιώτης-Αλέξιος
        \\Α.Μ.: 03400274
        \\e-mail: spanakis01@gmail.com
    \end{flushright}

    \begin{flushleft}
        \vfill
        Ιωάννης Καραπαρίσης
        \\Α.Μ.: 09321011
        \\e-mail: ikaraparisis@gmail.com
    \end{flushleft}
    
    %%
\end{titlepage}

\newpage


\section*{Θεωρητικό Υπόβαθρο}

\subsection{Mel-Frequency Cepstral Coefficients (MFCCs)}

Τα Mel-Frequency Cepstral Coefficients (MFCCs) αποτελούν ένα από τα πιο διαδεδομένα ακουστικά χαρακτηριστικά που χρησιμοποιούνται στην αναγνώριση ομιλίας. Η εξαγωγή τους βασίζεται στην ανάλυση των σημάτων φωνής με μια ειδικά σχεδιασμένη συστοιχία φίλτρων (Mel filterbank), η οποία είναι εμπνευσμένη από τον μη γραμμικό τρόπο με τον οποίο το ανθρώπινο αυτί αντιλαμβάνεται τις συχνότητες του ήχου.

Η διαδικασία εξαγωγής των MFCCs περιλαμβάνει τα εξής βήματα:

\begin{enumerate}
    \item Διαίρεση του σήματος σε μικρά τμήματα (frames) με επικάλυψη
    \item Εφαρμογή παραθύρου (συνήθως Hamming) σε κάθε frame
    \item Υπολογισμός του μετασχηματισμού Fourier (FFT)
    \item Εφαρμογή φίλτρων Mel-scale στο φάσμα ισχύος
    \item Λογαρίθμηση των ενεργειών που προκύπτουν
    \item Εφαρμογή Διακριτού Μετασχηματισμού Συνημιτόνου (DCT)
    \item Επιλογή των πρώτων συντελεστών (συνήθως 12-13) ως MFCCs
\end{enumerate}

Τα MFCCs είναι ιδιαίτερα χρήσιμα επειδή συμπυκνώνουν τις πληροφορίες του φάσματος του σήματος με τρόπο που προσομοιάζει την ανθρώπινη αντίληψη του ήχου, δίνοντας μεγαλύτερη έμφαση στις χαμηλές συχνότητες.

\subsection{Γλωσσικά Μοντέλα (Language Models)}

Τα γλωσσικά μοντέλα (Language Models) στην αναγνώριση ομιλίας αναπαριστούν την πιθανότητα εμφάνισης συγκεκριμένων ακολουθιών λέξεων ή φωνημάτων στη γλώσσα. Στην παρούσα άσκηση χρησιμοποιήσαμε στατιστικά γλωσσικά μοντέλα n-gram, συγκεκριμένα unigram και bigram μοντέλα, για την αναπαράσταση των πιθανοτήτων εμφάνισης μεμονωμένων φωνημάτων και ζευγών φωνημάτων, αντίστοιχα.

Τα n-gram μοντέλα βασίζονται στην υπόθεση Markov, υποθέτοντας ότι η πιθανότητα εμφάνισης ενός φωνήματος εξαρτάται μόνο από τα $n-1$ προηγούμενα φωνήματα. Έτσι:

\begin{itemize}
    \item Στο unigram μοντέλο, η πιθανότητα κάθε φωνήματος θεωρείται ανεξάρτητη από τα προηγούμενα φωνήματα.
    \item Στο bigram μοντέλο, η πιθανότητα κάθε φωνήματος εξαρτάται μόνο από το αμέσως προηγούμενο φώνημα.
\end{itemize}

Η ποιότητα ενός γλωσσικού μοντέλου μπορεί να αξιολογηθεί με τη μετρική της perplexity, η οποία αντιπροσωπεύει το μέσο αριθμό εναλλακτικών επιλογών που "βλέπει" το μοντέλο σε κάθε βήμα πρόβλεψης. Χαμηλότερες τιμές perplexity υποδεικνύουν καλύτερο γλωσσικό μοντέλο.

\subsection{Φωνητικά Μοντέλα (Acoustic Models)}

Τα φωνητικά μοντέλα (Acoustic Models) αναπαριστούν τη σχέση μεταξύ των ακουστικών χαρακτηριστικών του σήματος ομιλίας και των φωνητικών μονάδων (φωνήματα στην περίπτωσή μας). Στην άσκηση αυτή, χρησιμοποιήσαμε δύο τύπους ακουστικών μοντέλων:

\begin{enumerate}
    \item \textbf{Μονοφωνικό GMM-HMM}: Σε αυτό το μοντέλο, κάθε φώνημα μοντελοποιείται ανεξάρτητα από το φωνητικό του περιβάλλον, χρησιμοποιώντας ένα Κρυφό Μαρκοβιανό Μοντέλο (HMM) με καταστάσεις που οι πιθανότητες εκπομπής τους μοντελοποιούνται με Μείγματα Γκαουσιανών Κατανομών (GMM).
    
    \item \textbf{Τριφωνικό GMM-HMM}: Σε αυτό το πιο σύνθετο μοντέλο, κάθε φώνημα μοντελοποιείται λαμβάνοντας υπόψη το φωνητικό του περιβάλλον, δηλαδή το προηγούμενο και το επόμενο φώνημα. Αυτή η προσέγγιση επιτρέπει στο μοντέλο να συλλάβει φαινόμενα συνάρθρωσης.
\end{enumerate}

Στα μοντέλα GMM-HMM, τα Κρυφά Μαρκοβιανά Μοντέλα χρησιμοποιούνται για να μοντελοποιήσουν τη χρονική δομή και εξέλιξη των φωνημάτων, ενώ τα Μείγματα Γκαουσιανών Κατανομών χρησιμοποιούνται για να μοντελοποιήσουν την κατανομή των ακουστικών χαρακτηριστικών σε κάθε κατάσταση του HMM.

\section*{Βήματα προπαρασκευής}

\subsection{Προετοιμασία Δεδομένων}

Το πρώτο βήμα της υλοποίησης αφορούσε την κατάλληλη προετοιμασία των δεδομένων για επεξεργασία από το Kaldi. Συγκεκριμένα:

\begin{enumerate}
    \item Δημιουργήσαμε την κατάλληλη δομή φακέλων (data/train, data/dev, data/test) για τα σύνολα εκπαίδευσης, επαλήθευσης και αποτίμησης.
    
    \item Για κάθε σύνολο δεδομένων, δημιουργήσαμε τα απαραίτητα αρχεία:
    \begin{itemize}
        \item \textbf{uttids}: Περιέχει τα μοναδικά αναγνωριστικά των εκφωνήσεων.
        \item \textbf{utt2spk}: Αντιστοιχίζει κάθε εκφώνηση στον ομιλητή της.
        \item \textbf{wav.scp}: Περιέχει τις διαδρομές προς τα αρχεία ήχου.
        \item \textbf{text}: Περιέχει τις φωνημικές μεταγραφές των εκφωνήσεων.
    \end{itemize}
    
    \item Μετατρέψαμε τα κείμενα των εκφωνήσεων σε ακολουθίες φωνημάτων χρησιμοποιώντας το λεξικό που παρασχέθηκε, μετατρέποντας όλους τους χαρακτήρες σε πεζούς, αφαιρώντας ειδικούς χαρακτήρες (εκτός από αποστρόφους), και προσθέτοντας το φώνημα σιωπής "sil" στην αρχή και το τέλος κάθε ακολουθίας.
\end{enumerate}

Η προετοιμασία των δεδομένων υλοποιήθηκε με τη χρήση Python και Bash scripts, όπως το \texttt{prepare\_data.py} και το \texttt{prepare\_usc\_data.sh}.

\subsection{Δημιουργία Γλωσσικού Μοντέλου}

Για τη δημιουργία του γλωσσικού μοντέλου, ακολουθήσαμε τα εξής βήματα:

\begin{enumerate}
    \item Δημιουργήσαμε τα απαραίτητα αρχεία στον φάκελο \texttt{data/local/dict}:
    \begin{itemize}
        \item \texttt{silence\_phones.txt} και \texttt{optional\_silence.txt}: Περιέχουν μόνο το φώνημα σιωπής "sil".
        \item \texttt{nonsilence\_phones.txt}: Περιέχει όλα τα υπόλοιπα φωνήματα, ένα ανά γραμμή και ταξινομημένα.
        \item \texttt{lexicon.txt}: Περιέχει μια 1-1 αντιστοιχία των φωνημάτων με τον εαυτό τους.
        \item \texttt{extra\_questions.txt}: Κενό αρχείο.
    \end{itemize}
    
    \item Δημιουργήσαμε τα αρχεία \texttt{lm\_train.text}, \texttt{lm\_dev.text}, και \texttt{lm\_test.text} προσθέτοντας τις ειδικές μονάδες <s> και </s> στην αρχή και το τέλος κάθε πρότασης.
    
    \item Χρησιμοποιήσαμε το εργαλείο \texttt{build-lm.sh} του πακέτου IRSTLM για να δημιουργήσουμε τα ενδιάμεσα γλωσσικά μοντέλα unigram και bigram σε μορφή .ilm.gz.
    
    \item Μετατρέψαμε τα ενδιάμεσα μοντέλα σε μορφή ARPA με το εργαλείο \texttt{compile-lm}.
    
    \item Δημιουργήσαμε το FST του λεξικού της γλώσσας (L.fst) χρησιμοποιώντας την εντολή \texttt{prepare\_lang.sh} του Kaldi.
    
    \item Δημιουργήσαμε το FST της γραμματικής (G.fst) για τα μοντέλα unigram και bigram.
\end{enumerate}

\subsection{Εξαγωγή Ακουστικών Χαρακτηριστικών}

Για την εξαγωγή των ακουστικών χαρακτηριστικών:

\begin{enumerate}
    \item Ρυθμίσαμε κατάλληλα το αρχείο \texttt{mfcc.conf} για να επιτρέπει την υποδειγματοληψία των αρχείων ήχου (τα αρχεία είχαν συχνότητα δειγματοληψίας 22050 Hz, ενώ η ρύθμιση ήταν για 16000 Hz).
    
    \item Χρησιμοποιήσαμε την εντολή \texttt{make\_mfcc.sh} του Kaldi για να εξάγουμε τα MFCCs και για τα τρία σύνολα δεδομένων (train, dev, test).
    
    \item Εφαρμόσαμε Κανονικοποίηση Μέσου και Διακύμανσης Cepstrum (CMVN) με την εντολή \texttt{compute\_cmvn\_stats.sh} για να βελτιώσουμε την ανθεκτικότητα των χαρακτηριστικών σε διαφορετικές συνθήκες ηχογράφησης και χαρακτηριστικά ομιλητών.
\end{enumerate}

Τα εξαγόμενα χαρακτηριστικά MFCC είχαν διάσταση 13 (12 συντελεστές cepstrum συν ενέργεια) για κάθε πλαίσιο.

\subsection{Εκπαίδευση Ακουστικών Μοντέλων}

Στη συνέχεια, προχωρήσαμε στην εκπαίδευση των ακουστικών μοντέλων:

\begin{enumerate}
    \item \textbf{Μονοφωνικό Μοντέλο}:
    \begin{itemize}
        \item Εκπαιδεύσαμε ένα μονοφωνικό GMM-HMM μοντέλο χρησιμοποιώντας την εντολή \texttt{train\_mono.sh}.
        \item Δημιουργήσαμε τους γράφους HCLG για το μονοφωνικό μοντέλο, τόσο για το unigram όσο και για το bigram γλωσσικό μοντέλο, με την εντολή \texttt{mkgraph.sh}.
        \item Αποκωδικοποιήσαμε τις προτάσεις των συνόλων επαλήθευσης (dev) και αποτίμησης (test) χρησιμοποιώντας τον αλγόριθμο Viterbi με την εντολή \texttt{decode.sh}.
    \end{itemize}
    
    \item \textbf{Τριφωνικό Μοντέλο}:
    \begin{itemize}
        \item Πραγματοποιήσαμε ευθυγράμμιση (alignment) των φωνημάτων χρησιμοποιώντας το μονοφωνικό μοντέλο με την εντολή \texttt{align\_si.sh}.
        \item Εκπαιδεύσαμε ένα τριφωνικό GMM-HMM μοντέλο χρησιμοποιώντας τα alignments και την εντολή \texttt{train\_deltas.sh}.
        \item Δημιουργήσαμε τους γράφους HCLG για το τριφωνικό μοντέλο, τόσο για το unigram όσο και για το bigram γλωσσικό μοντέλο.
        \item Αποκωδικοποιήσαμε εκ νέου τις προτάσεις των συνόλων επαλήθευσης και αποτίμησης.
    \end{itemize}
\end{enumerate}

\section{Πειραματικά Αποτελέσματα}

\subsection{Απόδοση Γλωσσικών Μοντέλων}

Τα γλωσσικά μοντέλα αξιολογήθηκαν με βάση το μέτρο perplexity στα σύνολα επαλήθευσης (dev) και αποτίμησης (test). Παρατηρήσαμε ότι το bigram μοντέλο παρείχε παρόμοια απόδοση με το unigram μοντέλο στο συγκεκριμένο πρόβλημα αναγνώρισης φωνημάτων, κάτι που μπορεί να οφείλεται στο περιορισμένο μέγεθος του συνόλου δεδομένων εκπαίδευσης.

\subsection{Απόδοση Ακουστικών Μοντέλων}

Η απόδοση των ακουστικών μοντέλων αξιολογήθηκε με βάση το Phone Error Rate (PER), το οποίο υπολογίζεται ως:

\begin{equation}
PER = 100 \cdot \frac{\text{insertions} + \text{substitutions} + \text{deletions}}{\text{#phonemes}}
\end{equation}


\bibliographystyle{plainnat}
\bibliography{references}

\end{document}